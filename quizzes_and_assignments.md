<div dir="rtl">

# سوالات کوییز و پروژه‌های LLM

## فصل 1: موارد استفاده و چرخه عمر پروژه و آشنایی با Hugging Face

### سوالات کوییز

1. تعامل با مدل‌های زبان بزرگ (LLM) با مدل‌های یادگیری ماشین سنتی متفاوت است. کار با LLMها شامل ورودی زبان طبیعی است که به عنوان _____ شناخته می‌شود و منجر به خروجی از مدل زبان بزرگ می‌شود که به عنوان _____ شناخته می‌شود.

    - درخواست قابل تنظیم، Completion  
    - پرامپت، Completion  
    - درخواست پیش‌بینی، پاسخ پیش‌بینی  
    - پرامپت، LLM تنظیم‌شده  

2. مدل‌های زبان بزرگ (LLM) قادر به انجام چندین وظیفه هستند که از موارد استفاده مختلف پشتیبانی می‌کنند. کدام یک از وظایف زیر از مورد استفاده تبدیل کامنت‌های کد به کد قابل اجرا پشتیبانی می‌کند؟

    - ترجمه  
    - بازیابی اطلاعات  
    - خلاصه‌سازی متن  
    - فراخوانی اقدامات از متن  

3. کدام کاربرد از LLM ها می‌تواند در یک متن اسم سازمان‌ها را برای ما مشخص کند؟

    - استخراج موجودیت  
    - بازیابی اطلاعات  
    - خلاصه‌سازی متن  
    - فراخوانی اقدامات از متن  

4. کدام یک از موارد زیر، مزیت اصلی معماری "ترنسفورمر" (Transformer) نسبت به "RNN" (شبکه عصبی بازگشتی) در مدیریت وابستگی‌های طولانی‌مدت است؟

    - شبکه عصبی بازگشتی قادر به یادگیری گرامر و ساختار زبان بهتری هستند.  
    - شبکه عصبی بازگشتی از حافظه کاری بزرگ‌تری استفاده می‌کنند.  
    - ترنسفورمرها از مکانیسم خودتوجهی استفاده می‌کنند.  
    - شبکه عصبی بازگشتی برای پردازش موازی طراحی شده‌اند.  

5. مکانیزم self-attention چیست؟

    - توانایی ترنسفورمر برای تجزیه و تحلیل عملکرد خود  
    - تمرکز مدل بر بخش‌های مختلف دنباله ورودی  
    - معیاری برای سنجش درک زبان  
    - تکنیکی برای بهبود تعمیم مدل  

6. "توکن‌سازی" به چه معناست؟

    - آموزش مدل برای پیش‌بینی کلمه بعدی  
    - تولید جملات تصادفی  
    - تبدیل کاراکترها به واحدهای عددی  
    - ارزیابی کیفیت خروجی  

7. کدام یک از انواع معماری‌های ترنسفورمر در ساخت LLMها استفاده می‌شود؟

    - Encoder-Only، Decoder-Only، Decoder-Decoder  
    - Decoder-Only، Encoder-Only، Hybrid  
    - Encoder-Only، Decoder-Only، Encoder-Decoder  
    - Decoder-Only، Encoder-Decoder، Decoder-Decoder  

8. RNNها برای هوش مصنوعی مولد بهتر هستند. درست یا غلط؟

    - درست  
    - غلط  

9. کدام پارامتر زیر بر "خلاقیت" یا "تصادفی بودن" خروجی LLM تأثیر می‌گذارد؟

    - Max Tokens  
    - Repetition Penalty  
    - Temperature  
    - K-top  

### پروژه‌ها

#### تمرین عملی 1-1

- بررسی خروجی با `max_new_tokens=10`  
- بررسی تغییرات با فعال‌سازی `do_sample=True` و تغییر `temperature`  
- تحلیل تنظیماتی که خروجی بهتری نسبت به خلاصه انسانی دارند  

#### تمرین عملی 1-2

- گفت‌و‌گو را خلاصه کنید (zero-shot)  
- پرامپت ترجمه به انگلیسی بنویسید  
- (اختیاری) با مدل دیگری مانند mistral نیز تست کنید  

---

## فصل 2: پیش‌آموزش LLM و قوانین مقیاس‌پذیری

### سوالات کوییز

1. کدام معماری هدفش حدس زدن توکن ماسک شده است؟

    - Autoencoder  
    - Autoregressive  
    - Sequence-to-sequence  

2. کدام معماری برای ترجمه مناسب است؟

    - Autoencoder  
    - Autoregressive  
    - Sequence-to-sequence  

3. آیا همیشه باید اندازه مدل را افزایش داد؟

    - درست  
    - غلط  

4. جایگزین‌های مناسب برای مقیاس‌بندی چیستند؟

    - Batch size  
    - Model size  
    - Dataset size  
    - Compute budget  

5. آیا می‌توان Data Parallelism را با Model Parallelism ترکیب کرد؟

    - درست  
    - غلط  

---

## فصل 3: تنظیم دقیق با دستورالعمل‌ها و ارزیابی

### سوالات کوییز

1. جاهای خالی را پر کنید:  
...  

2. پدیده کاهش عملکرد وظایف دیگر در اثر فاین‌تیون چیست؟  
...  

3. در مورد Multi-task Finetuning، کدام درست است؟  
...  

4. کدام معیار برای ترجمه متن استفاده می‌شود؟  
...  

5. کدام معیار برای خلاصه‌سازی متن استفاده می‌شود؟  
...  

### پروژه‌ها

#### تمرین عملی 3-1

- ساخت دیتاست کوچک با ترجمه انگلیسی به فارسی  
- مقایسه BLEU score با Google Translate  

---

## فصل 4: PEFT

### سوالات کوییز

1. آیا LLMهای کوچک‌تر در few-shot مشکل دارند؟  
...  

2. کدام روش‌های PEFT هستند؟  
...  

3. آیا PEFT حافظه را کاهش می‌دهد؟  
...  

4. نحوه کار LoRA چیست؟  
...  

5. Soft Prompt چیست؟  
...  

6. آیا Prompt Tuning همه هایپرپارامترها را تنظیم می‌کند؟  
...  

### پروژه‌ها

#### تمرین عملی 4-1

- پیاده‌سازی Prompt Tuning برای ترجمه ماشینی  
- مقایسه BLEU با تمرین قبلی  

#### مینی پروژه 1: خلاصه‌سازی خبر با PEFT

- با استفاده از QLoRA روی TinyLlama یا Gemma2  
- خروجی: Colab notebook، مثال، تحلیل  

#### مینی پروژه 2: NER فارسی با PEFT

- آموزش روی دیتاست NER فارسی با HooshvareLab  
- تحویل: نوت‌بوک Jupyter، گزارش، نتایج ارزیابی  

---

## فصل 5: بازخورد انسانی و یادگیری تقویتی

### سوالات کوییز

1. جاهای خالی را پر کنید: agent و action space  
...  

2. "Proximal" در PPO یعنی چه؟  
...  

3. نقش KL Divergence در PPO چیست؟  
...  

4. هدف اصلی DPO چیست؟  
...  

5. داده آموزشی در DPO چیست؟  
...  

6. تفاوت GRPO با DPO چیست؟  
...  

7. داده آموزشی GRPO چیست؟  
...  

8. تفاوت روش‌های PPO, DPO, GRPO  
...  

9. در مورد Constitutional AI، کدام صحیح‌اند؟  
...  

### پروژه‌ها

- آموزش مدل با DPO روی Orca DPO Pairs  
- استفاده از زیرمجموعه ۱۰۰۰ تایی در صورت محدودیت  

---

## فصل 6: بهینه‌سازی برای استقرار

### سوالات کوییز

1. فرآیند Knowledge Distillation چیست؟  
...  

2. تفاوت کوانتیزیشن و هرس مدل چیست؟  
...  

---

## فصل 7: ساخت اپلیکیشن‌های هوشمند با LLM

### سوالات کوییز

1. RAG چگونه LLM را بهبود می‌دهد؟  
...  

2. چگونه Information Retrieval کاربرد را بهبود می‌دهد؟  
...  

3. نقش Retriever در RAG چیست؟  
...  

4. نقش Embeddings در LangChain چیست؟  
...  

5. چرا PDF باید chunk شود؟  
...  

6. ساختار ساده Pipeline در LangChain چیست؟  
...  

7. PAL چیست؟  
...  

8. تمرکز ReAct چیست؟  
...  

### پروژه‌ها

- تست نوت‌بوک 17 با PDF دلخواه  
- تغییر retriever و بهبود پاسخ‌دهی  

</div>
